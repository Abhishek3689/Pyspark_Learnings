{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/14 22:12:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('handling_data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark=spark.read.csv('../data/Student_marks.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-------+-------+\n",
      "|  Name|   Sex|Math|Science|English|\n",
      "+------+------+----+-------+-------+\n",
      "| Sunny|Female|  87|     91|     81|\n",
      "| Bobby|  Male|  67|     56|     71|\n",
      "|  Tina|Female|null|     54|     90|\n",
      "| Reeta|  null|  71|   null|   null|\n",
      "|Sachin|  Male|null|     67|     51|\n",
      "| Honey|Female|  80|     76|   null|\n",
      "+------+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Math: integer (nullable = true)\n",
      " |-- Science: integer (nullable = true)\n",
      " |-- English: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+-------+-------+\n",
      "| Name|   Sex|Math|Science|English|\n",
      "+-----+------+----+-------+-------+\n",
      "|Sunny|Female|  87|     91|     81|\n",
      "|Bobby|  Male|  67|     56|     71|\n",
      "+-----+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop(how='any',thresh=5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-------+-------+\n",
      "|  Name|   Sex|Math|Science|English|\n",
      "+------+------+----+-------+-------+\n",
      "| Sunny|Female|  87|     91|     81|\n",
      "| Bobby|  Male|  67|     56|     71|\n",
      "|  Tina|Female|null|     54|     90|\n",
      "|Sachin|  Male|null|     67|     51|\n",
      "| Honey|Female|  80|     76|   null|\n",
      "+------+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop(how='all',thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-------+-------+\n",
      "|  Name|   Sex|Math|Science|English|\n",
      "+------+------+----+-------+-------+\n",
      "| Sunny|Female|  87|     91|     81|\n",
      "| Bobby|  Male|  67|     56|     71|\n",
      "|  Tina|Female|null|     54|     90|\n",
      "| Reeta|  null|  71|   null|   null|\n",
      "|Sachin|  Male|null|     67|     51|\n",
      "| Honey|Female|  80|     76|   null|\n",
      "+------+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-------+-------+\n",
      "|  Name|   Sex|Math|Science|English|\n",
      "+------+------+----+-------+-------+\n",
      "| Sunny|Female|  87|     91|     81|\n",
      "| Bobby|  Male|  67|     56|     71|\n",
      "|  Tina|Female|null|     54|     90|\n",
      "| Reeta|  null|  71|   null|   null|\n",
      "|Sachin|  Male|null|     67|     51|\n",
      "| Honey|Female|  80|     76|   null|\n",
      "+------+------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.fill(\"Missing\",subset=['Math','English']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 21.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/config/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed numpy-1.24.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=Imputer(inputCols=['Math','Science','English'],outputCols=['{}_imputed '.format(c) for c in ['Math','Science','English']]).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-------+-------+-------------+----------------+----------------+\n",
      "|  Name|   Sex|Math|Science|English|Math_imputed |Science_imputed |English_imputed |\n",
      "+------+------+----+-------+-------+-------------+----------------+----------------+\n",
      "| Sunny|Female|  87|     91|     81|           87|              91|              81|\n",
      "| Bobby|  Male|  67|     56|     71|           67|              56|              71|\n",
      "|  Tina|Female|null|     54|     90|           76|              54|              90|\n",
      "| Reeta|  null|  71|   null|   null|           71|              68|              73|\n",
      "|Sachin|  Male|null|     67|     51|           76|              67|              51|\n",
      "| Honey|Female|  80|     76|   null|           80|              76|              73|\n",
      "+------+------+----+-------+-------+-------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer2=Imputer(inputCol='Sex',outputCol='Sex_imputed').setStrategy('mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|   Sex|Math|\n",
      "+------+----+\n",
      "|Female|  87|\n",
      "|  Male|  67|\n",
      "|Female|null|\n",
      "|  null|  71|\n",
      "|  Male|null|\n",
      "|Female|  80|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('Sex','Math').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (50360747.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_spark.withColumn(\"Sex_encoded\",[if s=='Female'  0 else 1 for s in df_spark['Sex']])\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn(\"Sex_encoded\",[if s=='Female'  0 else 1 for s in df_spark['Sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
